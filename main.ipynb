{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de99deee-7dcb-43b4-a900-8a0a3e0e9f32",
   "metadata": {},
   "source": [
    "# DATA522 Final Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458cb4c4-fc6e-4404-92b8-ebf89ddfeca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries for reading in Parquet and OCR\n",
    "%pip install pyarrow\n",
    "%pip install ocrmac\n",
    "# %pip install pytesseract\n",
    "%pip install easyocr\n",
    "\n",
    "# Pre-trained sentiment analysis model\n",
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e8312c0-6622-4dbc-ba7b-ba18128f72d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import easyocr\n",
    "from ocrmac import ocrmac\n",
    "import cv2\n",
    "import PIL\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c482254-d504-431d-86f8-27595f1b22f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all data Parquets\n",
    "def read_dataset(dirname):\n",
    "    training_filenames = [\n",
    "        filename for filename in os.listdir(dirname) if filename.endswith('.parquet') and filename.beginswith('train') \n",
    "    ]\n",
    "    return [\n",
    "        pd.read_parquet(f'{dirname}/{filename}').drop(columns = ['caption']) for filename in training_filenames\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5aea722-6e68-44e5-9cea-68c738d4f033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "state_easyocr = {\n",
    "    \"reader\": easyocr.Reader(['en'])\n",
    "}\n",
    "\n",
    "state_sentiment = {\n",
    "    \"pipeline\": pipeline(\"sentiment-analysis\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bbe7046-1ced-4ff9-843b-f01ad1e6c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes2cv2(image):\n",
    "    img_bytes = image['bytes']\n",
    "    return cv2.imdecode(\n",
    "        np.frombuffer(\n",
    "            img_bytes, \n",
    "            np.uint8\n",
    "        ),\n",
    "        cv2.IMREAD_COLOR_RGB\n",
    "    )\n",
    "# https://stackoverflow.com/questions/17170752/python-opencv-load-image-from-byte-string\n",
    "def imshow(image):\n",
    "    decoded_image = bytes2cv2(image)\n",
    "    plt.imshow(decoded_image)\n",
    "\n",
    "def analyze_sentiment(text, state_sentiment):\n",
    "    sentiment = state_sentiment[\"pipeline\"](text)[0]\n",
    "    if sentiment[\"label\"] == \"NEGATIVE\":\n",
    "        return -1 * sentiment[\"score\"]\n",
    "    return sentiment[\"score\"]\n",
    "\n",
    "def easyocr_filtertext(read_text):\n",
    "    return ' '.join(read_text).upper()\n",
    "    \n",
    "def ocr_easyocr(image, state):\n",
    "    decoded_image = bytes2cv2(image)\n",
    "    return easyocr_filtertext(state['reader'].readtext(decoded_image, detail = 0))\n",
    "\n",
    "def ocr_ocrmac(image):\n",
    "    return ' '.join(\n",
    "        [\n",
    "            ocr_tuple[0] \n",
    "            for ocr_tuple \n",
    "            in ocrmac.text_from_image(\n",
    "                PIL.Image.fromarray(\n",
    "                    bytes2cv2(image)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def text_sentiment_row(row):\n",
    "    text_ocrmac = ocr_ocrmac(row.image)\n",
    "    sentiment_ocrmac = analyze_sentiment(text_ocrmac, state_sentiment)\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"text_ocrmac\": text_ocrmac,\n",
    "            \"sentiment_ocrmac\": sentiment_ocrmac\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create pared-down dataset\n",
    "def text_sentiment(df):\n",
    "    df_ocr = pd.concat([df, df.apply(\n",
    "        text_sentiment_row,\n",
    "        axis = 1,\n",
    "        result_type = 'expand'\n",
    "    )], axis = 1)\n",
    "    return df_ocr\n",
    "\n",
    "def create_pared_dataset(dirname):\n",
    "    training_parquets = read_dataset(dirname)\n",
    "    \n",
    "    for i, training_parquet in enumerate(training_parquets):\n",
    "        text_sentiment(training_parquet).drop(columns = 'image').to_parquet(f'{dirname}/parquet_{i}-sentiment.parquet')\n",
    "\n",
    "def read_pared_dataset(dirname):\n",
    "    sentiment_filenames = [\n",
    "        filename for filename in os.listdir(dirname) if filename.endswith('.parquet') and not filename.beginswith('train')\n",
    "    ]\n",
    "    print(sentiment_filenames)\n",
    "    sentiment_parquets = [\n",
    "        pd.read_parquet(f'{dirname}/{filename}') for filename in sentiment_filenames\n",
    "    ]\n",
    "    return pd.concat(sentiment_parquets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54286a0a-6b0a-45a9-814a-ad48de2c3186",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'beginswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# create_pared_dataset('./data')\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m sentiment_dataset = \u001b[43mread_pared_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./data\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mread_pared_dataset\u001b[39m\u001b[34m(dirname)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_pared_dataset\u001b[39m(dirname):\n\u001b[32m     67\u001b[39m     sentiment_filenames = [\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         filename \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os.listdir(dirname) \u001b[38;5;28;01mif\u001b[39;00m filename.endswith(\u001b[33m'\u001b[39m\u001b[33m.parquet\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mfilename\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeginswith\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     69\u001b[39m     ]\n\u001b[32m     70\u001b[39m     \u001b[38;5;28mprint\u001b[39m(sentiment_filenames)\n\u001b[32m     71\u001b[39m     sentiment_parquets = [\n\u001b[32m     72\u001b[39m         pd.read_parquet(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m sentiment_filenames\n\u001b[32m     73\u001b[39m     ]\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'beginswith'"
     ]
    }
   ],
   "source": [
    "# create_pared_dataset('./data')\n",
    "sentiment_dataset = read_pared_dataset('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2de6f-17cf-4bce-9cfc-458622087347",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\".endswith"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
